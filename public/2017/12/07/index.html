<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>轮子：一个简单的node爬虫踩坑之路 | 程鹏飞的博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="一个简单的node爬虫踩坑之路准备工作最近在看爬虫相关的文章，偶然想起来尝试一下用node来实现一个简单的爬虫。但是爬别的多没意思，当然是爬美女图片啊。。。 这大概 node 里面造的最多的轮子了。 于是，我选取了下面的地址：美女图片戳我，简单分析后，我的目标是通过爬取首页的轮播图，然后爬取轮播图的直链后面的详情大图，并按照图片名称存到指定的文件夹中。大致流程是下面这个样子的：  看起来挺简单的，">
<meta property="og:type" content="article">
<meta property="og:title" content="轮子：一个简单的node爬虫踩坑之路">
<meta property="og:url" content="https://michaelooo.github.io/2017/12/07/index.html">
<meta property="og:site_name" content="程鹏飞的博客">
<meta property="og:description" content="一个简单的node爬虫踩坑之路准备工作最近在看爬虫相关的文章，偶然想起来尝试一下用node来实现一个简单的爬虫。但是爬别的多没意思，当然是爬美女图片啊。。。 这大概 node 里面造的最多的轮子了。 于是，我选取了下面的地址：美女图片戳我，简单分析后，我的目标是通过爬取首页的轮播图，然后爬取轮播图的直链后面的详情大图，并按照图片名称存到指定的文件夹中。大致流程是下面这个样子的：  看起来挺简单的，">
<meta property="og:locale" content="zh_ZN">
<meta property="og:image" content="https://t1.picb.cc/uploads/2017/12/06/px1gr.jpg">
<meta property="og:image" content="https://t1.picb.cc/uploads/2017/12/06/pxHd1.jpg">
<meta property="article:published_time" content="2017-12-07T10:20:00.000Z">
<meta property="article:modified_time" content="2023-03-01T07:59:35.682Z">
<meta property="article:author" content="Michael Cheng">
<meta property="article:tag" content="nodejs">
<meta property="article:tag" content="爬虫">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://t1.picb.cc/uploads/2017/12/06/px1gr.jpg">
  
  
    <link rel="icon" href="https://ws1.sinaimg.cn/large/86c7c947gy1g4sl65dqrtj20b40b478p.jpg">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <nav id="sub-nav">
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap"><form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://michaelooo.github.io"></form></div>
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
        <a class="main-nav-link" href="/">首页</a>
        
        <a class="main-nav-link" href="/archives">归档</a>
        
        <a class="main-nav-link" href="/resume/">关于</a>
        
      </nav>
    </div>
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">程鹏飞的博客</a>
      </h1>
      
    </div>
  </div>
  <!-- <script src="https://releases.leanapp.cn/leancloud/javascript-sdk/releases/download/v3.5.0/av-min.js"></script> -->
</header>

      <div class="outer">
        <section id="main"><article id="post-轮子：一个简单的node爬虫踩坑之路" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/12/07/" class="article-date">
  <time datetime="2017-12-07T10:20:00.000Z" itemprop="datePublished">2017-12-07</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/nodejs/">nodejs</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      轮子：一个简单的node爬虫踩坑之路
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h1 id="一个简单的node爬虫踩坑之路"><a href="#一个简单的node爬虫踩坑之路" class="headerlink" title="一个简单的node爬虫踩坑之路"></a>一个简单的node爬虫踩坑之路</h1><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>最近在看爬虫相关的文章，偶然想起来尝试一下用node来实现一个简单的爬虫。但是爬别的多没意思，当然是爬美女图片啊。。。</p>
<p>这大概 node 里面造的最多的轮子了。</p>
<p>于是，我选取了下面的地址：<a href="http://www.zbjuran.com/mei/" target="_blank" rel="noopener">美女图片戳我</a>，简单分析后，我的目标是通过爬取首页的轮播图，然后爬取轮播图的直链后面的详情大图，并按照图片名称存到指定的文件夹中。<br>大致流程是下面这个样子的：</p>
<p><img src="https://t1.picb.cc/uploads/2017/12/06/px1gr.jpg" alt="爬取的大致流程"></p>
<p>看起来挺简单的，选用的技术方案是：</p>
<ul>
<li><code>superagent</code>: 请求库</li>
<li><code>mkdirp</code>: 创建文件夹</li>
<li><code>async</code>: 控制并发请求</li>
<li><code>cheerio</code>: Dom操作库</li>
<li><code>fs</code>: 内置核心文件读写库</li>
</ul>
<h2 id="最终的效果"><a href="#最终的效果" class="headerlink" title="最终的效果"></a>最终的效果</h2><p><img src="https://t1.picb.cc/uploads/2017/12/06/pxHd1.jpg" alt="哈哈"></p>
<h2 id="源码："><a href="#源码：" class="headerlink" title="源码："></a>源码：</h2><pre><code>// 关键在于理清异步流程

&#39;use strict&#39;
let fs = require(&quot;fs&quot;);
let cheerio = require(&#39;cheerio&#39;);
let asyncQuene = require(&quot;async&quot;).queue;
let request = require(&#39;superagent&#39;);
require(&#39;superagent-charset&#39;)(request);

const config = {
    urlPre: &#39;http://www.zbjuran.com&#39;,
    indexUrl: &#39;http://www.zbjuran.com/mei/&#39;,
    downloadConcurrent: 2, 
};

let getHtmlAsync = (url) =&gt; {
    return new Promise((resolve,reject) =&gt; {
        request.get(url).charset(&#39;gbk&#39;).end((err,res) =&gt; {
            err ? reject(err) : resolve(cheerio.load(res.text));
        })
    })
}

let dowloadImg = (albumList) =&gt; {
    console.log(&#39;开始下载图片&#39;);
    const folder = &#39;./grils/&#39;;
    fs.existsSync(folder, status =&gt; {
        status ? &#39;&#39; : fs.mkdirSync(folder);
    })
    let downloadCount = 0;
    let queue = asyncQuene( ({ url: albumUrl, title: albumTitle},done) =&gt; {
        request.get(albumUrl).end(function (err, res) {
            if (err) {
                console.log(err);
                done();
            } else {
                fs.writeFile(`./${folder}/${albumTitle}-${++downloadCount}.jpg`, res.body, function (err) {
                    err ? console.log(err) : console.log(`${albumTitle}保存一张`);
                    done();
                });
            }
        });
    },config.downloadConcurrent);

    queue.drain = () =&gt; {
        console.log(&#39;所有图片已经下载&#39;);
    }

    let imgListTemp = [];
    albumList.forEach(function ({ title, imgList }) {
        console.log(title,imgList);
        imgList.forEach(function (url) {
            imgListTemp.push({ title: title, url: url });
        });
    });
    console.log(&#39;sssss&#39;,albumList,imgListTemp);
    queue.push(imgListTemp);//将所有任务加入队列
}

let getIndexAsync = () =&gt; {
    return new Promise((resolve, reject) =&gt;{
        console.log(&#39;进入主页，开始获取目标url&#39;);
        let targetUrl = [];
        let queue = asyncQuene(async (url, done) =&gt; {
            try {
                let $ = await getHtmlAsync(url);
                console.log(`成功获取主页${url}`);
                $(&#39;div.changeDiv a&#39;).each( (index,value) =&gt; {
                    targetUrl.push({
                        title: value.attribs.title,
                        url: `${config.urlPre}${value.attribs.href}`,
                        imgList: []
                    })
                });
            } catch (err) {
                console.log(`在访问${url}出现以下错误：${err}`);
            }
            finally {
                done();
            }
        },config.downloadConcurrent);
        queue.drain = () =&gt; {
            console.log(&#39;已成功生成目标Url&#39;);
            resolve(targetUrl);
        }

        queue.push(config.indexUrl);
    })
}

let getTargetAsync = (targetUrl) =&gt; {
    return new Promise((resolve, reject) =&gt;{
        console.log(&#39;进入目标页，开始获取目标url&#39;);
        let queue = asyncQuene(async ({ url: url, title: title, imgList },done) =&gt; {
            try {
                let $ = await getHtmlAsync(url);
                console.log(`成功获取主页${url}`);
                let imgLength = $(&#39;div.page &gt; li&#39;).length - 3;
                $(&#39;div.picbox img&#39;).each( (index,value) =&gt; {
                    let imgSrcPath = value.attribs.src;
                    imgList.push(`${config.urlPre}${value.attribs.src}`);
                    for (let i = 0,length = imgLength; i &lt; length; i++) {
                        if(i &gt;= 1){
                            imgList.push(`${config.urlPre}${imgSrcPath.replace(&#39;-0&#39;,&#39;-&#39;+i)}.jpg`);
                        }
                    }
                });
            } catch (err) {
                console.log(`在访问${url}出现以下错误：${err}`);
            }
            finally {
                done();
            }
        },config.downloadConcurrent);

        queue.drain = () =&gt; {
            console.log(&#39;已成功获取到所有图片的Url&#39;);
            resolve(targetUrl);
        }

        queue.push(targetUrl);
    })
}


let spider = async () =&gt; {
    // let albumList = await getAlbumsAsync();//获取所有画册URL
    // albumList = await getImageListAsync(albumList);//根据画册URL获取画册里的所有图片URL
    // downloadImg(albumList);//下载画册里面的所有图片
    let targetUrl = await getIndexAsync();
    targetUrl = await getTargetAsync(targetUrl);
    dowloadImg(targetUrl);
}

spider();
</code></pre><h2 id="划重点"><a href="#划重点" class="headerlink" title="划重点"></a>划重点</h2><h3 id="1-当爬取网页编码为-gb2312的网页的时候，爬到的内容中文显示是乱码"><a href="#1-当爬取网页编码为-gb2312的网页的时候，爬到的内容中文显示是乱码" class="headerlink" title="1.当爬取网页编码为 gb2312的网页的时候，爬到的内容中文显示是乱码"></a>1.当爬取网页编码为 <code>gb2312</code>的网页的时候，爬到的内容中文显示是乱码</h3><p>这个问题的原因其实是挺清晰的，就是网页编码与本地编码不一致或不支持引起的。以为只是个小问题，但是在找解决办法的时候却纠结了我很久，查询了网上相关资料，<strong>有说使用 <code>iconv</code> 解码<code>decode</code>一下就可以，然并卵</strong>，<strong>有说使用encoding的，其实也没用</strong>。其实最后查阅资料得出的原因是，<code>superagent</code>只支持utf-8的编码，如果需要支持其他的需要引用一个官方的库：<code>superagent-charset</code>,使用方法如下：</p>
<pre><code>const request = require(&#39;superagent&#39;);
require(&#39;superagent-charset&#39;)(request);
//请求
request.get(&#39;xxx&#39;).set(&#39;gbk&#39;).end(xxxxx)
</code></pre><p>如此，即可正常返回中文</p>
<h3 id="2-异步操作用-async-来控制"><a href="#2-异步操作用-async-来控制" class="headerlink" title="2. 异步操作用 async 来控制"></a>2. 异步操作用 async 来控制</h3><p>对于下载图片，访问 url 这样存在异步的操作，如果操作对后面程序的执行有影响，最好使用 <a href="http://caolan.github.io/async/" target="_blank" rel="noopener"><code>async</code></a> 库来控制异步流程，类似的还有 <a href="https://github.com/JacksonTian/eventproxy" target="_blank" rel="noopener"><code>eventproxy</code></a>。</p>
<p>下面是一个使用来<code>async</code>来控制请求队列的官网示例，</p>
<pre><code>// create a queue object with concurrency 2
var q = async.queue(function(task, callback) {
    console.log(&#39;hello &#39; + task.name);
    callback();
}, 2);

// assign a callback
q.drain = function() {
    console.log(&#39;all items have been processed&#39;);
};

// add some items to the queue
q.push({name: &#39;foo&#39;}, function(err) {
    console.log(&#39;finished processing foo&#39;);
});
q.push({name: &#39;bar&#39;}, function (err) {
    console.log(&#39;finished processing bar&#39;);
});

// add some items to the queue (batch-wise)
q.push([{name: &#39;baz&#39;},{name: &#39;bay&#39;},{name: &#39;bax&#39;}], function(err) {
    console.log(&#39;finished processing item&#39;);
});

// add some items to the front of the queue
q.unshift({name: &#39;bar&#39;}, function (err) {
    console.log(&#39;finished processing bar&#39;);
});
</code></pre><p>其实官网有好多栗子，近期还会抽时间好好研究一下类似异步流程库的具体实现。</p>
<h3 id="3-404错误。获取不到资源"><a href="#3-404错误。获取不到资源" class="headerlink" title="3. 404错误。获取不到资源"></a>3. 404错误。获取不到资源</h3><p>这个其实还好，主要是网站为了防爬的措施，可以尝试一下方法来试试看：</p>
<ul>
<li>设置<code>user-agent</code></li>
<li>降低请求的并发量</li>
<li>更换IP</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>虽然只是一个简单的爬虫，但是发现自己对于 <code>promise</code> 这种的异步流程还不是很熟悉，这点需要重点掌握。</p>
<p>另外，从爬虫的角度来说，node现在的库已经很完善了，还有 <code>phantomjs</code>，<code>node-crawl</code> 这种操作更6的库存在，掌握一门工具很容易，更重要的是要学会制作工具。</p>
<p>最后，练习爬虫只是出于对技术的热爱，莫要乱爬。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://michaelooo.github.io/2017/12/07/" data-id="clepflm8h005nfbmn7wdnzgbe" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/nodejs/" rel="tag">nodejs</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a></li></ul>

    </footer>
  </div>
  
    
 
<script src="/jquery/jquery.min.js"></script>

  <div id="random_posts">
    <h2>推荐文章</h2>
    <div class="random_posts_ul">
      <script>
          var random_count =4
          var site = {BASE_URI:'/'};
          function load_random_posts(obj) {
              var arr=site.posts;
              if (!obj) return;
              // var count = $(obj).attr('data-count') || 6;
              for (var i, tmp, n = arr.length; n; i = Math.floor(Math.random() * n), tmp = arr[--n], arr[n] = arr[i], arr[i] = tmp);
              arr = arr.slice(0, random_count);
              var html = '<ul>';
            
              for(var j=0;j<arr.length;j++){
                var item=arr[j];
                html += '<li><strong>' + 
                item.date + ':&nbsp;&nbsp;<a href="' + (site.BASE_URI+item.uri) + '">' + 
                (item.title || item.uri) + '</a></strong>';
                if(item.excerpt){
                  html +='<div class="post-excerpt">'+item.excerpt+'</div>';
                }
                html +='</li>';
                
              }
              $(obj).html(html + '</ul>');
          }
          $('.random_posts_ul').each(function () {
              var c = this;
              if (!site.posts || !site.posts.length){
                  $.getJSON(site.BASE_URI + 'js/posts.js',function(json){site.posts = json;load_random_posts(c)});
              } 
               else{
                load_random_posts(c);
              }
          });
      </script>
    </div>
  </div>

    
<nav id="article-nav">
  
    <a href="/2017/12/08/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">上一篇</strong>
      <div class="article-nav-title">
        
          关于JS事件队列的一些总结
        
      </div>
    </a>
  
  
    <a href="/2017/12/06/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">下一篇</strong>
      <div class="article-nav-title">搭建 GIT 服务器教程</div>
    </a>
  
</nav>

  
</article>
 
     
<div class="comments" id="comments">
      
</div>


  

</section>
           
    <aside id="sidebar">
  
    

  
    
    <div class="widget-wrap">
    
      <div class="widget" id="toc-widget-fixed">
      
        <strong class="toc-title">文章目录</strong>
        <div class="toc-widget-list">
              <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84node%E7%88%AC%E8%99%AB%E8%B8%A9%E5%9D%91%E4%B9%8B%E8%B7%AF"><span class="toc-number">1.</span> <span class="toc-text">一个简单的node爬虫踩坑之路</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C"><span class="toc-number">1.1.</span> <span class="toc-text">准备工作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%80%E7%BB%88%E7%9A%84%E6%95%88%E6%9E%9C"><span class="toc-number">1.2.</span> <span class="toc-text">最终的效果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%BA%90%E7%A0%81%EF%BC%9A"><span class="toc-number">1.3.</span> <span class="toc-text">源码：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%92%E9%87%8D%E7%82%B9"><span class="toc-number">1.4.</span> <span class="toc-text">划重点</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%BD%93%E7%88%AC%E5%8F%96%E7%BD%91%E9%A1%B5%E7%BC%96%E7%A0%81%E4%B8%BA-gb2312%E7%9A%84%E7%BD%91%E9%A1%B5%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E7%88%AC%E5%88%B0%E7%9A%84%E5%86%85%E5%AE%B9%E4%B8%AD%E6%96%87%E6%98%BE%E7%A4%BA%E6%98%AF%E4%B9%B1%E7%A0%81"><span class="toc-number">1.4.1.</span> <span class="toc-text">1.当爬取网页编码为 gb2312的网页的时候，爬到的内容中文显示是乱码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%BC%82%E6%AD%A5%E6%93%8D%E4%BD%9C%E7%94%A8-async-%E6%9D%A5%E6%8E%A7%E5%88%B6"><span class="toc-number">1.4.2.</span> <span class="toc-text">2. 异步操作用 async 来控制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-404%E9%94%99%E8%AF%AF%E3%80%82%E8%8E%B7%E5%8F%96%E4%B8%8D%E5%88%B0%E8%B5%84%E6%BA%90"><span class="toc-number">1.4.3.</span> <span class="toc-text">3. 404错误。获取不到资源</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">1.5.</span> <span class="toc-text">总结</span></a></li></ol></li></ol>
          </div>
      </div>
    </div>

  
    

  
    
  
    
  
    

  
    
  
    <!--微信公众号二维码-->


  
    <!-- 去掉浏览量统计 -->
<!-- 
    <div class="widget-wrap">
    <h3 class="widget-title">浏览数目</h3>
    <div class="widget">
      <ul class="popularlist">
      </ul>
    </div>
  </div>
 -->
  
</aside>

      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-left">
      &copy; 2014 - 2023 Michael Cheng&nbsp;|&nbsp;
      主题 <a href="https://github.com/giscafer/hexo-theme-cafe/" target="_blank">Cafe</a>
      <a target="_blank" href="http://www.beian.miit.gov.cn/" style="display:inline-block;text-decoration:none;height:20px;line-height:20px;margin-left: 10px;">
          <img style="float: left; width: 20px;" src="//img.alicdn.com/tfs/TB1..50QpXXXXX7XpXXXXXXXXXX-40-40.png">
          <span style="float:left;height:20px;line-height:20px;margin: 0px 0px 0px 5px; color:#939393;">粤ICP备17162335号</span>
      </a>
    </div>
     <div id="footer-right">
      联系方式&nbsp;|&nbsp;422208170@qq.com
    </div>
  </div>
</footer>
 
<script src="/jquery/jquery.min.js"></script>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">首页</a>
  
    <a href="/archives" class="mobile-nav-link">归档</a>
  
    <a href="/resume/" class="mobile-nav-link">关于</a>
  
</nav>
    <img class="back-to-top-btn" src="https://t1.picb.cc/uploads/2021/05/04/ZEnbna.png"/>
<script>
// Elevator script included on the page, already.
window.onload = function() {
  var elevator = new Elevator({
    selector:'.back-to-top-btn',
    element: document.querySelector('.back-to-top-btn'),
    duration: 1000 // milliseconds
  });
}
</script>
     
<script src="/js/is.js"></script>



  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>


<script src="/js/elevator.js"></script>


<script src="/js/fundebug.1.9.0.min.js"></script>


<!--page counter part-->
<script>
  function addCount (Counter) {
    var curpage_count; 
    url=$('.article-date').attr('href').trim();
    title = $('.article-title').text().trim();
    var query=new AV.Query(Counter);
    //use url as unique idnetfication
    query.equalTo("url",url);
    query.find().then(function(results){
      if(results.length>0) {
          var counter=results[0];
          counter.fetchWhenSave(true); //get recent result
          counter.increment("time");
          counter.save();
          curpage_count = counter.attributes.time + 1;
          $('.article-inner').append('<p style="color:#999;margin-left:20px">（本文已被访问'+curpage_count+'次）</p>');
      } else {
        var newcounter=new Counter();
        newcounter.set("title",title);
        newcounter.set("url",url);
        newcounter.set("time",1);
        newcounter.save(null,{
            success: function(newcounter){
            //alert('New object created');
            },
            error: function(newcounter,error){
            alert('Failed to create');
            }
            });
        curpage_count = 1;
        $('.article-inner').append('<p style="color:#999;margin-left:20px">（本文已被访问'+curpage_count+'次）</p>');
      }
    },function(error){
        //find null is not a error
        alert('Error:'+error.code+" "+error.message);
    });
  }

  $(function(){
      // fundebug INIT
      fundebug.apikey = '311c1dc8f056512d95a8a459b5d14892078dc69e4686b5f704142485c2c04620';

      // init
      var APP_ID = 'P8zI4n1RVVKeFqFoDDcJXtxB-gzGzoHsz';
      var APP_KEY = 'XygRBwRtUGj8XJLClnpGKXQQ';

      AV.init({
        appId: APP_ID,
        appKey: APP_KEY
      });

      var Counter=AV.Object.extend("Counter");
      //only increse visit counting when intering a page
      if ($('.article-title').length == 1)
        addCount(Counter);
      var query=new AV.Query(Counter);
      query.descending("time");
      // the sum of popular posts
      query.limit(10); 
      query.find()
      .then(
        function(results){
          for(var i=0;i<results.length;i++)    
            {
                var counter=results[i];
                title=counter.get("title");
                url=counter.get("url");
                time=counter.get("time");
                // add to the popularlist widget
                showcontent=title+" ("+time+")";
                //notice the "" in href
                $('.popularlist').append('<li><a href="'+url+'">'+showcontent+'</a></li>');
            }
          },
          function(error){
            alert("Error:"+error.code+" "+error.message);
          });
  });
</script>

  </div>
</body>
</html>